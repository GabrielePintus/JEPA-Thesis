{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596b1ffb",
   "metadata": {},
   "source": [
    "# Loss analysis\n",
    "\n",
    "In this notebook we compute the loss value for each data point in the dataset to gain an insight on how the model is behaveaing and where it fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9ae3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from matplotlib import gridspec\n",
    "import imageio\n",
    "from IPython.display import Video\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.encoder_temporal import VICRegJEPAEncoder\n",
    "from src.data.dataset import PointMazeTransitions\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff7e2a",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5dfbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] Frames resized to 64×64\n",
      "[Dataset] Loaded 10 episodes, 1000 transitions.\n",
      "[Dataset] Frame shape: (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = PointMazeTransitions(\n",
    "    \"data/train_trajectories_10_100_4_64.npz\",\n",
    "    normalize=True,\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4bc27",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f0ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VICRegJEPAEncoder.load_from_checkpoint(\"checkpoints/visual_encoder/last.ckpt\", strict=False)\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b598ee7",
   "metadata": {},
   "source": [
    "Compute the loss for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d1c767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/gabrielepintus/.conda/envs/py12/lib/python3.12/site-packages/vicreg_loss/vicreg.py:91: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1839.)\n",
      "  std = x.std(dim=0)\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 273.92it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = list()\n",
    "states = list()\n",
    "with torch.inference_mode():\n",
    "    for batch in tqdm(dataloader):\n",
    "        (state_curr, frame_curr), action, (state_next, frame_next), _ = batch\n",
    "        states.append(state_curr.numpy())\n",
    "        batch = (\n",
    "            (state_curr.to(device), frame_curr.to(device)),\n",
    "                action.to(device),\n",
    "                (state_next.to(device), frame_next.to(device)), None\n",
    "            )\n",
    "        loss = model.shared_step(batch, -1)\n",
    "        loss = { k: v.item() for k, v in loss.items() if \"curr\" in k }\n",
    "        losses.append(loss)\n",
    "\n",
    "states = np.concatenate(states, axis=0)\n",
    "n_losses = len(losses[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a39c0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== recon_loss_curr | threshold=0.0975807 | positives=10 ===\n",
      "Feature importances:\n",
      "1. feature_0 (32.08%)\n",
      "2. feature_2 (26.49%)\n",
      "3. feature_3 (25.17%)\n",
      "4. feature_1 (16.25%)\n",
      "\n",
      "=== proprio_recon_loss_curr | threshold=0.0938972 | positives=10 ===\n",
      "Feature importances:\n",
      "1. feature_0 (32.08%)\n",
      "2. feature_2 (26.49%)\n",
      "3. feature_3 (25.17%)\n",
      "4. feature_1 (16.25%)\n",
      "\n",
      "=== visual_recon_loss_curr | threshold=0.00425967 | positives=10 ===\n",
      "Feature importances:\n",
      "1. feature_2 (31.47%)\n",
      "2. feature_3 (30.97%)\n",
      "3. feature_0 (19.46%)\n",
      "4. feature_1 (18.10%)\n",
      "Skipping vcreg_cls_curr: all NaN\n",
      "\n",
      "=== vcreg_patch_curr | threshold=4.27778 | positives=10 ===\n",
      "Feature importances:\n",
      "1. feature_0 (26.81%)\n",
      "2. feature_2 (25.15%)\n",
      "3. feature_1 (24.97%)\n",
      "4. feature_3 (23.07%)\n",
      "Skipping vcreg_state_curr: all NaN\n",
      "\n",
      "=== vicreg_cross_curr | threshold=1.72793 | positives=10 ===\n",
      "Feature importances:\n",
      "1. feature_0 (37.77%)\n",
      "2. feature_3 (22.31%)\n",
      "3. feature_2 (21.54%)\n",
      "4. feature_1 (18.38%)\n",
      "\n",
      "=== state_from_patches_loss_curr | threshold=0.102001 | positives=10 ===\n",
      "Feature importances:\n",
      "1. feature_1 (31.92%)\n",
      "2. feature_3 (29.53%)\n",
      "3. feature_0 (21.92%)\n",
      "4. feature_2 (16.63%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "rankings = dict()\n",
    "\n",
    "for loss_name in losses[0].keys():\n",
    "    loss_values = np.array([loss[loss_name] for loss in losses], dtype=float)\n",
    "    if np.all(np.isnan(loss_values)):\n",
    "        print(f\"Skipping {loss_name}: all NaN\")\n",
    "        continue\n",
    "\n",
    "    # fill NaNs with median so thresholding works\n",
    "    if np.isnan(loss_values).any():\n",
    "        loss_values[np.isnan(loss_values)] = np.nanmedian(loss_values)\n",
    "\n",
    "    threshold = np.percentile(loss_values, 99)\n",
    "    labels = (loss_values >= threshold).astype(int)\n",
    "    n_pos = labels.sum()\n",
    "\n",
    "    print(f\"\\n=== {loss_name} | threshold={threshold:.6g} | positives={n_pos} ===\")\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(states, labels)\n",
    "\n",
    "    # feature importances\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"Feature importances:\")\n",
    "    for rank in range(states.shape[1]):\n",
    "        i = indices[rank]\n",
    "        print(f\"{rank+1}. feature_{i} ({importances[i]:.2%})\")\n",
    "\n",
    "    rankings[loss_name] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed13cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total position cost: 48\n",
      "Total velocity cost: 36\n"
     ]
    }
   ],
   "source": [
    "pos_cost, vel_cost = 0, 0\n",
    "for k, v in rankings.items():\n",
    "    _pos_cost = sum(np.where(v < 2)[0] ** 2)\n",
    "    _vel_cost = sum(np.where((v >=2) & (v <4))[0] **2)\n",
    "    pos_cost += _pos_cost\n",
    "    vel_cost += _vel_cost\n",
    "print(f\"\\nTotal position cost: {pos_cost}\")\n",
    "print(f\"Total velocity cost: {vel_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
